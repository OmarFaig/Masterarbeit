{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-18T20:52:07.512904636Z",
     "start_time": "2024-02-18T20:52:03.968166958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import seedformer_dim128\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import open3d as o3d\n",
    "import os\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "import gc\n",
    "#torch.cuda.empty_cache()\n",
    "#gc.collect()\n",
    "from torch.optim.lr_scheduler import StepLR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset and Dataloader\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "717e2fba24cdcbb8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RacingDataset(Dataset):\n",
    "    def __init__(self,root_dir,target_points=4731):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = os.listdir(root_dir)\n",
    "        self.filter_file_list = self.filter_list()\n",
    "        self.target_points = target_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filter_file_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        pcd_path = os.path.join(self.root_dir,self.filter_file_list[index])\n",
    "        pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "        points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "        #padded_points = self.pad_point_cloud(pcd.points)\n",
    "\n",
    "        return points,pcd_path\n",
    "\n",
    "    #def pad_point_cloud(self, points):\n",
    "    #    num_points = len(points)\n",
    "    #    if num_points < self.target_points:\n",
    "    #        # Pad the point cloud with zeros to match the target size\n",
    "    #        padded_points = torch.cat([torch.tensor(points), torch.zeros(self.target_points - num_points, 3)])\n",
    "    #    else:\n",
    "    #        padded_points = torch.tensor(points)\n",
    "    #    return padded_points\n",
    "    \n",
    "    def filter_list(self):\n",
    "        '''\n",
    "        Filter the inputs so that only pcds with more than 50 points are included in the training\n",
    "        :return:\n",
    "        '''\n",
    "        filtered_list=[]\n",
    "        for filename in self.file_list:\n",
    "            pcd = o3d.io.read_point_cloud(os.path.join(self.root_dir,filename))\n",
    "            points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "            if len(points)>=0:\n",
    "                filtered_list.append(filename)\n",
    "        return filtered_list\n",
    "   \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T20:52:07.521314031Z",
     "start_time": "2024-02-18T20:52:07.515944904Z"
    }
   },
   "id": "18531201d491e956",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#pcd_pad=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/cropped/sim/018840.pcd\")\n",
    "#pcd_pad_tens=torch.tensor(pcd_pad.points,dtype=torch.float32)\n",
    "#print(pcd_pad_tens[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T20:52:07.532028842Z",
     "start_time": "2024-02-18T20:52:07.518414651Z"
    }
   },
   "id": "2125c1abfbfd223f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15136/800869091.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  pcd_pad_tens = torch.tensor(pcd_pad.points, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "<__main__.RacingDataset object at 0x7f0949e3aa10>\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    # Define the target number of points for padding\n",
    "    target_num_points = 4731\n",
    "    \n",
    "    # Pad each point cloud to have target_num_points points\n",
    "    padded_points_batch = []\n",
    "    for points, _ in batch:\n",
    "        num_points_to_pad = target_num_points - points.size(0)\n",
    "        if num_points_to_pad > 0:\n",
    "            pad = torch.zeros(num_points_to_pad, 3, dtype=torch.float32)\n",
    "            padded_points = torch.cat((points, pad), dim=0)\n",
    "        else:\n",
    "            padded_points = points[:target_num_points]  # Trim to target_num_points if exceeds\n",
    "        padded_points_batch.append(padded_points)\n",
    "    \n",
    "    padded_points = pad_sequence(padded_points_batch, batch_first=True, padding_value=0)\n",
    "    \n",
    "    paths = [item[1] for item in batch]\n",
    "    \n",
    "    return padded_points, paths\n",
    "# Load the largest point cloud\n",
    "pcd_pad = o3d.io.read_point_cloud(\"/home/omar/TUM/Data/cropped/sim/018840.pcd\")\n",
    "pcd_pad_tens = torch.tensor(pcd_pad.points, dtype=torch.float32)\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\", target_points=len(pcd_pad_tens))\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "\n",
    "print(len(dataloader))\n",
    "print(dataloader.dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T20:52:10.086991732Z",
     "start_time": "2024-02-18T20:52:07.535331475Z"
    }
   },
   "id": "bb205b36c1489ab0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#from numba import cuda\n",
    "# \n",
    "#cuda.select_device(0) # choosing second GPU \n",
    "#cuda.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T20:52:10.090077577Z",
     "start_time": "2024-02-18T20:52:10.085777311Z"
    }
   },
   "id": "cdf884c0e1ffd630",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 750/750 [06:30<00:00,  1.92batch/s, loss=0.381]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.38075175643479453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/100: 100%|██████████| 750/750 [06:30<00:00,  1.92batch/s, loss=0.00242]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.002417574243542428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/100:  68%|██████▊   | 510/750 [04:25<02:04,  1.92batch/s, loss=0.00133]"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "#del model\n",
    "model=seedformer_dim128(up_factors=[1, 2, 2])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "epochs=100\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)  # Reduce LR by a factor of 0.1 every 30 epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss=0\n",
    "    # Wrap the DataLoader with tqdm to track progress\n",
    "    with tqdm(enumerate(dataloader, 0), total=len(dataloader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch') as pbar:\n",
    "        for i, data in pbar:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)  # Move data to GPU if available\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            losses = []\n",
    "\n",
    "            for input_pc, output_pc in zip(inputs, outputs):\n",
    "                # Calculate Chamfer Distance loss using pytorch3d.loss.chamfer_distance\n",
    "                loss, _ = chamfer_distance(input_pc.unsqueeze(0), output_pc.unsqueeze(0))\n",
    "                losses.append(loss)\n",
    "\n",
    "            loss = torch.mean(torch.stack(losses))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(loss=running_loss / (i + 1))  # Update tqdm progress bar with the current loss\n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "    print(f'Epoch {epoch+1} Loss: {running_loss / len(dataloader)}')  # Log the epoch loss\n",
    "\n",
    "print('Finished Training')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-18T20:52:10.091084624Z"
    }
   },
   "id": "ca233b98555d8fc7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#model=None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T20:49:15.749629820Z",
     "start_time": "2024-02-18T20:49:15.741088866Z"
    }
   },
   "id": "ad42762ce106b60e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Apply the model and visualize differences\u001B[39;00m\n\u001B[1;32m     17\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 18\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m()\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset, dataloader, name \u001B[38;5;129;01min\u001B[39;00m [(simulation_dataset, simulation_dataloader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSimulation\u001B[39m\u001B[38;5;124m\"\u001B[39m), \n\u001B[1;32m     21\u001B[0m                                   (real_dataset, real_dataloader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReal\u001B[39m\u001B[38;5;124m\"\u001B[39m)]:\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(dataloader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProcessing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m dataset\u001B[39m\u001B[38;5;124m'\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpoint cloud\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "# Define your model and dataset class\n",
    "\n",
    "# Load simulation dataset\n",
    "simulation_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/sim\")\n",
    "simulation_dataloader = DataLoader(simulation_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=collate_fn)\n",
    "\n",
    "# Load real dataset\n",
    "real_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\")\n",
    "real_dataloader = DataLoader(real_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=collate_fn)\n",
    "\n",
    "# Select a subset of samples\n",
    "num_samples = 3\n",
    "\n",
    "# Apply the model and visualize differences\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "\n",
    "for dataset, dataloader, name in [(simulation_dataset, simulation_dataloader, \"Simulation\"), \n",
    "                                  (real_dataset, real_dataloader, \"Real\")]:\n",
    "    for i, data in enumerate(tqdm(dataloader, desc=f'Processing {name} dataset', unit='point cloud')):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        \n",
    "        inputs, paths = data\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        original_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(inputs.squeeze().cpu().numpy()))\n",
    "        original_pc.paint_uniform_color([1, 0, 0])  # Paint original point cloud in red\n",
    "\n",
    "        reconstructed_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(outputs.squeeze().cpu().numpy()))\n",
    "        reconstructed_pc.paint_uniform_color([0, 1, 0])  # Paint reconstructed point cloud in green\n",
    "\n",
    "        o3d.visualization.draw_geometries([original_pc, reconstructed_pc], window_name=f\"{name} - Sample {i+1}\")\n",
    "#model=None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T20:49:21.837321633Z",
     "start_time": "2024-02-18T20:49:17.353647468Z"
    }
   },
   "id": "f7b4375fbe9eb442",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Notes#\n",
    "'''\n",
    "input threshold adjust - \n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-18T20:39:45.454457388Z"
    }
   },
   "id": "4c4231e6d2e1734",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
