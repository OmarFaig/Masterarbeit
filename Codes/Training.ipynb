{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training.ipynb\n",
    " In this notebook mainly different functions are tested. Also the adapted datasets are also generated here.\n",
    " In the following cells dataloader , training loop and additional functions are defined"
   ],
   "id": "d646c928f454c4e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import seedformer_dim128\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import open3d as o3d\n",
    "import os\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import utils.utils as utils\n",
    "from utils.utils import get_loss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import logging"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dataset and Dataloader\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "Below is the implementation of custom dataset/dataloader. Additionally there is a collate function. The number of points in eaach pointcloud is \n",
    "different. In order to make them equal collate function is defined."
   ],
   "id": "717e2fba24cdcbb8"
  },
  {
   "cell_type": "code",
   "source": [
    "class RacingDataset(Dataset):\n",
    "    def __init__(self,root_dir):#4731\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = os.listdir(root_dir)\n",
    "        self.filter_file_list = self.filter_list()\n",
    "       # self.target_points = target_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filter_file_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        pcd_path = os.path.join(self.root_dir,self.filter_file_list[index])\n",
    "        pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "        points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "\n",
    "        return points,pcd_path\n",
    "\n",
    "   \n",
    "    def filter_list(self):\n",
    "        '''\n",
    "        Filter the inputs so that only pcds with more than 50 points are included in the training\n",
    "        :return:\n",
    "        '''\n",
    "        filtered_list=[]\n",
    "        for filename in self.file_list:\n",
    "            pcd = o3d.io.read_point_cloud(os.path.join(self.root_dir,filename))\n",
    "            points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "            if len(points)>=0:\n",
    "                filtered_list.append(filename)\n",
    "        return filtered_list\n",
    "   \n",
    "\n",
    "# Load the largest point cloud\n",
    "pcd_pad = o3d.io.read_point_cloud(\"/home/omar/TUM/Data/cropped/sim/018840.pcd\")\n",
    "pcd_pad_tens = torch.tensor(pcd_pad.points, dtype=torch.float32)\n",
    "#print(len(pcd_pad_tens))\n",
    "# Create the dataset and dataloader\n",
    "dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\")\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=8,collate_fn=utils.collate_fn)\n",
    "\n",
    "print(len(dataloader))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18531201d491e956",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(torch.__version__)\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed0c8d51559b7f9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "This Python script trains a neural network model using SeedFormer for reconstructing 3D point clouds. Key functionalities include:\n",
    "* Model Setup: Initializes and configures a PointNet++ model (seedformer_dim128) for point cloud reconstruction.\n",
    "\n",
    "* Data Handling: Loads a custom dataset (RacingDataset) and sets up a DataLoader for efficient batch processing.\n",
    "\n",
    "* Training Loop: Iterates through epochs and batches, computing reconstruction losses using Chamfer Distance. Optimizes model parameters using Adam optimizer with learning rate scheduling.\n",
    "\n",
    "* Checkpoint Management: Saves model checkpoints based on validation loss improvements to facilitate resumable training and model evaluation.\n",
    "\n",
    "* Logging and Monitoring: Tracks training progress with average epoch losses and updates a progress bar (tqdm) to visualize training status.\n",
    "\n",
    "* This script enables training of a deep learning model for reconstructing point clouds, showcasing foundational practices in neural network training and evaluation.\n",
    "SeedFormer: https://arxiv.org/pdf/2207.10315"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e28a0ccc7563064"
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "#del model\n",
    "# Initialize your model\n",
    "model = seedformer_dim128(up_factors=[1, 2, 4, 4])  # 512 1024 4096 9192\n",
    "\n",
    "# Define device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "# Define DataLoader\n",
    "dataset = RacingDataset(root_dir=\"/dev/shm/IAC/SeedFormer_2602_npy/cropped/real\")\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=8, collate_fn=utils.collate_fn)\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=3e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "epochs=200\n",
    "# Define paths for checkpoint\n",
    "checkpoint_path = 'training2205v002_pad3000_knn_big.pth'\n",
    "\n",
    "# Check if a checkpoint exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_loss = checkpoint['loss']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    logging.info(f\"Checkpoint loaded. Resuming training from epoch {start_epoch}. Best loss so far: {best_loss}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    best_loss = float('inf')\n",
    "    logging.info(\"No checkpoint found. Starting training from scratch.\")\n",
    "    logging.info(model)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    running_loss = 0\n",
    "\n",
    "    # Wrap the DataLoader with tqdm to track progress\n",
    "    with tqdm(enumerate(dataloader, 0), total=len(dataloader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "        for i, data in pbar:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)  # Move data to GPU if available\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Apply the model to the entire batch\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            losses = []\n",
    "            for input_pc, output_pc in zip(inputs, outputs[-1]):\n",
    "                loss, _ = chamfer_distance(input_pc.unsqueeze(0), output_pc.unsqueeze(0))\n",
    "                losses.append(loss * 1e3)\n",
    "\n",
    "            loss = torch.mean(torch.stack(losses))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(loss=running_loss / (i + 1))  # Update tqdm progress bar with the current loss\n",
    "\n",
    "            # Compute losses\n",
    "            # loss_total, losses, gts = get_loss(outputs, inputs, inputs, sqrt=False)\n",
    "            # Backpropagation and optimization\n",
    "            # loss_total.backward()\n",
    "            # optimizer.step()\n",
    "            # Log the loss for monitoring\n",
    "            # running_loss += loss_total.item()\n",
    "            # cd_pc_item = losses[0].item()\n",
    "            # total_cd_pc += cd_pc_item\n",
    "            # cd_p1_item = losses[1].item()\n",
    "            # total_cd_p1 += cd_p1_item\n",
    "            # cd_p2_item = losses[2].item()\n",
    "            # total_cd_p2 += cd_p2_item\n",
    "            # cd_p3_item = losses[3].item()\n",
    "            # total_cd_p3 += cd_p3_item\n",
    "            # partial_item = losses[4].item()\n",
    "            # total_partial += partial_item\n",
    "            # Compute average losses for the batch\n",
    "            # avg_cdc = total_cd_pc / len(inputs)\n",
    "            # avg_cd1 = total_cd_p1 / len(inputs)\n",
    "            # avg_cd2 = total_cd_p2 / len(inputs)\n",
    "            # avg_cd3 = total_cd_p3 / len(inputs)\n",
    "            # avg_partial = total_partial / len(inputs)\n",
    "            # Update running loss\n",
    "            # print(\"len inputs\" , len(inputs))\n",
    "            # print(\"loss \",loss_total/len(inputs))\n",
    "            # Update progress bar with the current loss\n",
    "\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        scheduler.step(avg_loss)  # Use the average loss for the scheduler\n",
    "\n",
    "    # Compute average loss for the epoch\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    # Save checkpoint if current loss is the best seen so far\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': avg_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "    # Log the epoch loss\n",
    "    last_lr = optimizer.param_groups[0]['lr']  # Get the last learning rate\n",
    "    # logging.info(   f'Epoch {epoch + 1} Loss: {loss_total, avg_cd1, avg_cd2, avg_cd3, avg_partial} LR: {last_lr}')  # Log it into the file\n",
    "    logging.info(f'Epoch {epoch + 1} Loss: {avg_loss} LR: {last_lr}')\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "logging.log(train_losses)\n",
    "print('Finished Training')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca233b98555d8fc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## Save The Data\n",
    " Below code generates adapted datase using the trained model and applying it to the sim data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bea2b4076db53cd4"
  },
  {
   "cell_type": "code",
   "source": [
    "simulation_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/sim\")\n",
    "simulation_dataloader = DataLoader(simulation_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=utils.collate_fn)\n",
    "utils.apply_and_save_res(dataset=simulation_dataset,dataloader=simulation_dataloader,model=model,savedir=\"/home/omar/TUM/Data/reconstructed_cropped/sim_2205v002_pad3000_knn_big\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dc7f9fe7611c357",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "pcd=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/reconstructed_cropped/sim_2205v002_pad3000_knn_big/018845.pcd\")\n",
    "print(len(pcd.points))\n",
    "box=[\"Car\" ,0.0, 0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.18, 1.9 ,4.88 ,26.11 ,-5.9 ,0.59 ,0.02]\n",
    "utils.visualize(pcl=pcd,bbox_coordinates=box)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d4e513c17deabb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## \"Stitch\" the data\n",
    "the generated car point clouds are then copied back to the original simulation scene."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6b07375205c94ec"
  },
  {
   "cell_type": "code",
   "source": [
    "reconstructed_car_path=\"/home/omar/TUM/Data/reconstructed_cropped/sim_2205v002_pad3000_knn_big/\"\n",
    "original_sim_path=\"/home/omar/TUM/data_MA/m1695833/Sim2RealDistributionAlignedDataset/sim/data/pcl/\"\n",
    "bbox_path=\"/home/omar/TUM/data_MA/m1695833/Sim2RealDistributionAlignedDataset/sim/data/label\"\n",
    "\n",
    "npy_final_path=\"/home/omar/TUM/Data/SeedFormer_2602_npy/reconstructed_2205v002_pad3000_knn_big/points/\"\n",
    "file_car_list=[]\n",
    "for filename_car in os.listdir(reconstructed_car_path):\n",
    "    file_car_list.append(filename_car)\n",
    "    txt=filename_car.replace('.pcd',\".txt\")\n",
    "    bbox = (open(bbox_path+\"/\"+txt, \"r\")).read().split()\n",
    "    original_pcd = o3d.io.read_point_cloud(original_sim_path+filename_car)\n",
    "    filename_=filename_car.split(\".\")[0]\n",
    "\n",
    "    reconstructed_car= o3d.io.read_point_cloud(reconstructed_car_path +\"/\"+ filename_car)\n",
    "    crop_invert=utils.crop_invert_stitch(original_pcd,reconstructed_car, bbox)\n",
    "    np_array=np.asarray(crop_invert.points)\n",
    "    np.save(npy_final_path+filename_,np_array)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb96cfc20a8049ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Additional help and test functoins ",
   "metadata": {
    "collapsed": false
   },
   "id": "5512f6b90a1a2862"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Functions for finding the biggest pcd\n",
    "\n",
    "def count_points_in_pcd(file_path):\n",
    "    pcd = o3d.io.read_point_cloud(file_path)\n",
    "    return len(pcd.points)\n",
    "\n",
    "def find_pcd_with_most_points(folder_path):\n",
    "    max_points = 0\n",
    "    max_pcd_file = None\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.pcd'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            num_points = count_points_in_pcd(file_path)\n",
    "            if num_points > max_points:\n",
    "                max_points = num_points\n",
    "                max_pcd_file = file_path\n",
    "\n",
    "    return max_pcd_file, max_points\n",
    "\n",
    "# Replace 'your_folder_path' with the path to your folder containing the PCD files\n",
    "folder_path = \"/home/omar/TUM/Data/cropped/real\"\n",
    "\n",
    "max_pcd_file, max_points = find_pcd_with_most_points(folder_path)\n",
    "if max_pcd_file:\n",
    "    print(f'The PCD file with the most points is: {max_pcd_file}')\n",
    "    print(f'Number of points: {max_points}')\n",
    "else:\n",
    "    print('No PCD files found in the specified folder.')\n"
   ],
   "id": "786bd8981521f110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#unpadding the point clouds\n",
    "import os\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# Path to the folder containing PCD files\n",
    "pcd_folder_path = '/home/omar/TUM/Data/reconstructed_cropped/sim_0404_30v004/'\n",
    "\n",
    "# List all PCD files in the folder\n",
    "file_list = [f for f in os.listdir(pcd_folder_path) if f.endswith('.pcd')]\n",
    "\n",
    "# Iterate through each PCD file\n",
    "for file_name in file_list:\n",
    "    # Read the point cloud\n",
    "    pcd = o3d.io.read_point_cloud(os.path.join(pcd_folder_path, file_name))\n",
    "    \n",
    "    # Get the numpy array of points\n",
    "    points = np.asarray(pcd.points)\n",
    "    \n",
    "    # Find the indices of non-padded points (non-zero points along the first axis)\n",
    "    non_padded_indices = np.where(np.any(points != 0, axis=1))[0]\n",
    "    \n",
    "    # Extract non-padded points\n",
    "    non_padded_points = points[non_padded_indices]\n",
    "    \n",
    "    # Update the point cloud with non-padded points\n",
    "    pcd.points = o3d.utility.Vector3dVector(non_padded_points)\n",
    "    print(len(non_padded_points))  # Print the number of non-padded points\n",
    "    print(non_padded_points[:5])   # Print the first 5 non-padded points\n",
    "\n",
    "    # Save the updated point cloud back to file\n",
    "    o3d.io.write_point_cloud(os.path.join(pcd_folder_path, file_name), pcd)\n"
   ],
   "id": "ba790299830aecb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "collapsed": false
   },
   "id": "d239d3f92368e731"
  },
  {
   "cell_type": "code",
   "source": [
    "# correcting the labels\n",
    "labels_folder=\"/home/omar/TUM/data_MA/m1695833/Sim2RealDistributionAlignedDataset/sim/data/label/\"\n",
    "save_folder=\"/home/omar/TUM/Data/SeedFormer_2602_npy/sim/labels/\"\n",
    "for label in os.listdir(labels_folder):\n",
    "    file = open(labels_folder+label)\n",
    "    bbox=file.read()\n",
    "    bbox_correct=utils.correct_bbox_label(bbox)\n",
    "    file.close()\n",
    "    file_write=open(save_folder+label,\"w+\")\n",
    "    file_write.write(\" \".join(bbox_correct))\n",
    "    file_write.close()\n",
    "    print(bbox_correct)\n",
    "    #print(items)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51ba0cfa6adeb93d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#visualization functions for fixing camera position\n",
    "def print_camera_pose(vis):\n",
    "    view_control = vis.get_view_control()\n",
    "    parameters = view_control.convert_to_pinhole_camera_parameters()\n",
    "    print(\"Camera Pose:\")\n",
    "    print(\"Extrinsic:\")\n",
    "    print(parameters.extrinsic)\n",
    "    print(\"Intrinsic:\")\n",
    "    print(parameters.intrinsic.intrinsic_matrix)\n",
    "    return False\n",
    "def set_camera_pose(vis, extrinsic, intrinsic):\n",
    "    # Convert extrinsic matrix to 4x4 numpy array\n",
    "    extrinsic_matrix = np.array(extrinsic)\n",
    "\n",
    "    # Get the window size from the visualizer\n",
    "    window_width = vis.get_view_control().convert_to_pinhole_camera_parameters().intrinsic.width\n",
    "    window_height = vis.get_view_control().convert_to_pinhole_camera_parameters().intrinsic.height\n",
    "\n",
    "    # Create an Open3D PinholeCameraIntrinsic object with the actual window size\n",
    "    intrinsic_o3d = o3d.camera.PinholeCameraIntrinsic(\n",
    "        window_width, window_height,\n",
    "        intrinsic[0, 0], intrinsic[1, 1],\n",
    "        intrinsic[0, 2], intrinsic[1, 2]\n",
    "    )\n",
    "\n",
    "    # Set camera parameters\n",
    "    parameters = vis.get_view_control().convert_to_pinhole_camera_parameters()\n",
    "    parameters.extrinsic = extrinsic_matrix\n",
    "    parameters.intrinsic = intrinsic_o3d\n",
    "\n",
    "    vis.get_view_control().convert_from_pinhole_camera_parameters(parameters)\n",
    "\n",
    "def visualize(point_cloud, bbox_coordinates, extrinsic, intrinsic):\n",
    "    # Create Open3D point cloud\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "\n",
    "    vis.get_render_option().point_size = 3.0\n",
    "  #  vis.get_render_option().background_color = np.zeros(3)\n",
    "\n",
    "    pcl = o3d.geometry.PointCloud()\n",
    "    pcl.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "    desired_color = [1, 0, 1]  # Red color\n",
    "    np_colors = np.tile(desired_color, (len(pcl.points), 1))\n",
    "   # pcl.colors = o3d.utility.Vector3dVector(np_colors)\n",
    "    # Create Open3D bounding box\n",
    "    bbox = None\n",
    "    if bbox_coordinates is not None:\n",
    "        bbox = o3d.geometry.OrientedBoundingBox(center=bbox_coordinates[:3],\n",
    "                                                 R=np.eye(3),\n",
    "                                                 extent=bbox_coordinates[3:6])\n",
    "        bbox.color = [1, 0, 0]  # Set bbox color to red\n",
    "\n",
    "    # Add geometries to the visualizer\n",
    "    vis.clear_geometries()\n",
    "    vis.add_geometry(pcl)\n",
    "    #if bbox:\n",
    "       # vis.add_geometry(bbox)\n",
    "\n",
    "    # Set initial view\n",
    "    view_control = vis.get_view_control()\n",
    "    #vis.poll_events()\n",
    "    #vis.update_renderer()\n",
    "  #  set_camera_pose(view_control, extrinsic, intrinsic)\n",
    "   # vis.register_key_callback(ord(\"P\"), print_camera_pose)\n",
    "\n",
    "    # Run the visualizer\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n"
   ],
   "id": "53abeae93efdf344",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
