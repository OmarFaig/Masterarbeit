{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-30T20:30:37.168585106Z",
     "start_time": "2024-01-30T20:30:37.157531024Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import seedformer_dim128\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import open3d as o3d\n",
    "import os\n",
    "from pytorch3d import loss "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset and Dataloader\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "717e2fba24cdcbb8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RacingDataset(Dataset):\n",
    "    def __init__(self,root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = os.listdir(root_dir)\n",
    "        self.filter_file_list = self.filter_list()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filter_file_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        pcd_path = os.path.join(self.root_dir,self.filter_file_list[index])\n",
    "        pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "        points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "\n",
    "        return points,pcd_path\n",
    "\n",
    "    def filter_list(self):\n",
    "        '''\n",
    "        Filter the inputs so that only pcds with more than 50 points are included in the training\n",
    "        :return:\n",
    "        '''\n",
    "        filtered_list=[]\n",
    "        for filename in self.file_list:\n",
    "            pcd = o3d.io.read_point_cloud(os.path.join(self.root_dir,filename))\n",
    "            points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "            if len(points)>=50:\n",
    "                filtered_list.append(filename)\n",
    "        return filtered_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T20:28:48.392962241Z",
     "start_time": "2024-01-30T20:28:48.384667386Z"
    }
   },
   "id": "18531201d491e956",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097\n",
      "<__main__.RacingDataset object at 0x7f3fb5e73100>\n"
     ]
    }
   ],
   "source": [
    "dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\")\n",
    "dataloader = DataLoader(dataset,batch_size=1,shuffle=True,num_workers=4)\n",
    "print(len(dataloader))\n",
    "print(dataloader.dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T20:45:04.603621030Z",
     "start_time": "2024-01-30T20:45:01.976899782Z"
    }
   },
   "id": "bb205b36c1489ab0",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward - npoints: None, self.nsample: 4\n",
      "sample xyz.shape  torch.Size([1, 3, 259])\n",
      "sample npoints: -   40\n",
      "forward - npoints: None, self.nsample: 8\n",
      "sample xyz.shape  torch.Size([1, 3, 40])\n",
      "sample npoints: -   20\n",
      "forward - npoints: None, self.nsample: None\n",
      "sample xyz.shape  torch.Size([1, 3, 20])\n",
      "sample npoints: -   None\n",
      "outoutputs 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The input pointclouds should be either Pointclouds objects or torch.Tensor of shape (minibatch, num_points, 3).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[60], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m#outputs = torch.stack([output for output in outputs if output.shape[0] == inputs.shape[1]], dim=0)\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutoutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;28mlen\u001B[39m(outputs))\n\u001B[0;32m---> 18\u001B[0m loss, _ \u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchamfer_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Backward pass and optimization\u001B[39;00m\n\u001B[1;32m     21\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/pytorch3d/loss/chamfer.py:229\u001B[0m, in \u001B[0;36mchamfer_distance\u001B[0;34m(x, y, x_lengths, y_lengths, x_normals, y_normals, weights, batch_reduction, point_reduction, norm, single_directional, abs_cosine)\u001B[0m\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSupport for 1 or 2 norm.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    228\u001B[0m x, x_lengths, x_normals \u001B[38;5;241m=\u001B[39m _handle_pointcloud_input(x, x_lengths, x_normals)\n\u001B[0;32m--> 229\u001B[0m y, y_lengths, y_normals \u001B[38;5;241m=\u001B[39m \u001B[43m_handle_pointcloud_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_lengths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_normals\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m cham_x, cham_norm_x \u001B[38;5;241m=\u001B[39m _chamfer_distance_single_direction(\n\u001B[1;32m    232\u001B[0m     x,\n\u001B[1;32m    233\u001B[0m     y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    242\u001B[0m     abs_cosine,\n\u001B[1;32m    243\u001B[0m )\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m single_directional:\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/pytorch3d/loss/chamfer.py:65\u001B[0m, in \u001B[0;36m_handle_pointcloud_input\u001B[0;34m(points, lengths, normals)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected normals to be of shape (N, P, 3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     66\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe input pointclouds should be either \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPointclouds objects or torch.Tensor of shape \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(minibatch, num_points, 3).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     69\u001B[0m     )\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X, lengths, normals\n",
      "\u001B[0;31mValueError\u001B[0m: The input pointclouds should be either Pointclouds objects or torch.Tensor of shape (minibatch, num_points, 3)."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model=seedformer_dim128(up_factors=[1, 2, 2])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "epochs=5\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(epochs):\n",
    "    #loss = loss.chamfer_distance()\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data  # Note: We have dummy labels here\n",
    "        inputs = inputs.to(device)  # Move data to GPU if available\n",
    "        optimizer.zero_grad()\n",
    "        #print(inputs)\n",
    "        outputs = model(inputs)        # Calculate Chamfer Distance loss\n",
    "        #outputs = torch.stack([output for output in outputs if output.shape[0] == inputs.shape[1]], dim=0)\n",
    "\n",
    "        print(\"outoutputs\",len(outputs))\n",
    "        loss, _ = loss.chamfer_distance(inputs, outputs)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T21:29:52.874307353Z",
     "start_time": "2024-01-30T21:29:52.635417405Z"
    }
   },
   "id": "ca233b98555d8fc7",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7b4375fbe9eb442"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
