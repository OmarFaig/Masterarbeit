{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-26T22:59:10.767538Z",
     "start_time": "2024-03-26T22:59:08.337385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import seedformer_dim128\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import open3d as o3d\n",
    "import os\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset and Dataloader\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "Below is the implementation of custom dataset/dataloader. Additionally there is a collate function. The number of points in eaach pointcloud is \n",
    "different. In order to make them equal collate function is defined."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "717e2fba24cdcbb8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RacingDataset(Dataset):\n",
    "    def __init__(self,root_dir,target_points=2990):#4731\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = os.listdir(root_dir)\n",
    "        self.filter_file_list = self.filter_list()\n",
    "        self.target_points = target_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filter_file_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        pcd_path = os.path.join(self.root_dir,self.filter_file_list[index])\n",
    "        pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "        points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "\n",
    "        return points,pcd_path\n",
    "\n",
    "   \n",
    "    def filter_list(self):\n",
    "        '''\n",
    "        Filter the inputs so that only pcds with more than 50 points are included in the training\n",
    "        :return:\n",
    "        '''\n",
    "        filtered_list=[]\n",
    "        for filename in self.file_list:\n",
    "            pcd = o3d.io.read_point_cloud(os.path.join(self.root_dir,filename))\n",
    "            points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "            if len(points)>=0:\n",
    "                filtered_list.append(filename)\n",
    "        return filtered_list\n",
    "   \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T22:59:10.773574Z",
     "start_time": "2024-03-26T22:59:10.769300Z"
    }
   },
   "id": "18531201d491e956",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7726/474309544.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  pcd_pad_tens = torch.tensor(pcd_pad.points, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the largest point cloud\n",
    "pcd_pad = o3d.io.read_point_cloud(\"/home/omar/TUM/Data/cropped/sim/018840.pcd\")\n",
    "pcd_pad_tens = torch.tensor(pcd_pad.points, dtype=torch.float32)\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\", target_points=len(pcd_pad_tens))\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=8, collate_fn=utils.collate_fn)\n",
    "\n",
    "print(len(dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T22:59:13.511912Z",
     "start_time": "2024-03-26T22:59:10.774557Z"
    }
   },
   "id": "bb205b36c1489ab0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T22:59:13.518504Z",
     "start_time": "2024-03-26T22:59:13.513310Z"
    }
   },
   "id": "ed0c8d51559b7f9b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T22:59:13.530606Z",
     "start_time": "2024-03-26T22:59:13.519430Z"
    }
   },
   "id": "f76a4d67ecfdff6c",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e28a0ccc7563064"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   4%|â–Ž         | 56/1499 [00:35<12:04,  1.99batch/s, loss=23.2]  "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "#del model\n",
    "model=seedformer_dim128(up_factors=[1, 2, 2])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "epochs=100\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=15, gamma=0.1)  # Reduce LR by a factor of 0.1 every 30 epochs\n",
    "\n",
    "# Initialize variables for checkpointing\n",
    "best_loss = float('inf')\n",
    "checkpoint_path = 'checkpoint.pth'\n",
    "log_file = 'training_log.txt'\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "\n",
    "    # Wrap the DataLoader with tqdm to track progress\n",
    "    with tqdm(enumerate(dataloader, 0), total=len(dataloader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "        for i, data in pbar:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)  # Move data to GPU if available\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            losses = []\n",
    "\n",
    "            for input_pc, output_pc in zip(inputs, outputs):\n",
    "                # Calculate Chamfer Distance loss using pytorch3d.loss.chamfer_distance\n",
    "                loss, _ = chamfer_distance(input_pc.unsqueeze(0), output_pc.unsqueeze(0))\n",
    "                losses.append(loss)\n",
    "\n",
    "            loss = torch.mean(torch.stack(losses))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(loss=running_loss / (i + 1))  # Update tqdm progress bar with the current loss\n",
    "\n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "    # Save checkpoint if current loss is the best seen so far\n",
    "    if running_loss < best_loss:\n",
    "        best_loss = running_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': running_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "    # Log the epoch loss in the log file\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f'Epoch {epoch + 1} Loss: {running_loss / len(dataloader)}\\n')\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-26T23:01:40.584350Z"
    }
   },
   "id": "ca233b98555d8fc7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save The Data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bea2b4076db53cd4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "del model\n",
    "import gc         # garbage collect library\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T22:59:02.824176Z",
     "start_time": "2024-03-26T22:59:02.624491Z"
    }
   },
   "id": "f56b812c034053a0",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "simulation_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/sim\")\n",
    "simulation_dataloader = DataLoader(simulation_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=utils.collate_fn)\n",
    "\n",
    "# Load real dataset\n",
    "real_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\")\n",
    "real_dataloader = DataLoader(real_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=utils.collate_fn)\n",
    "utils.apply_and_save_res(dataset=real_dataset,dataloader=real_dataloader,model=model,savedir=\"/home/omar/TUM/Data/reconstructed_cropped/real\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dc7f9fe7611c357",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## \"Stitch\" the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6b07375205c94ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create and save the new dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5512f6b90a1a2862"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correcting Labels\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d239d3f92368e731"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_folder=\"/home/omar/TUM/data_MA/m1695833/Sim2RealDistributionAlignedDataset/sim/data/label/\"\n",
    "save_folder=\"/home/omar/TUM/Data/SeedFormer_2602_npy/sim/labels/\"\n",
    "for label in os.listdir(labels_folder):\n",
    "    file = open(labels_folder+label)\n",
    "    bbox=file.read()\n",
    "    bbox_correct=utils.correct_bbox_label(bbox)\n",
    "    file.close()\n",
    "    file_write=open(save_folder+label,\"w+\")\n",
    "    file_write.write(\" \".join(bbox_correct))\n",
    "    file_write.close()\n",
    "    print(bbox_correct)\n",
    "    #print(items)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51ba0cfa6adeb93d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reconstructed_car_path=\"/home/omar/TUM/Data/combined/sim/\"\n",
    "#bbox_path=\"/home/omar/TUM/data_MA/m1695833/Sim2RealDistributionAlignedDataset/sim/data/label\"\n",
    "\n",
    "#original_sim_path=\"/home/omar/TUM/data_MA/m1695833/Sim2RealDistributionAlignedDataset/sim/data/pcl/\"\n",
    "original_sim_path=\"/home/omar/TUM/Data/reconstructed_scene/sim/\"\n",
    "#reconstructed_scene_path=\"/home/omar/TUM/Data/reconstructed_scene/sim/\"\n",
    "npy_final_path=\"/home/omar/TUM/Data/SeedFormer_2602_npy_zyx/reconstructed/points/\"\n",
    "file_car_list=[]\n",
    "for filename_car in os.listdir(reconstructed_car_path):\n",
    "    file_car_list.append(filename_car)\n",
    "    txt=filename_car.replace('.pcd',\".txt\")\n",
    "   # bbox = (open(bbox_path+\"/\"+txt, \"r\")).read().split()\n",
    "    original_pcd = o3d.io.read_point_cloud(original_sim_path+filename_car)\n",
    "    filename_=filename_car.split(\".\")[0]\n",
    "    #if  (int)(filename_)<=24995:#<>\n",
    "        \n",
    "        #print(filename_)\n",
    "    np_array=np.asarray(original_pcd.points)#.pcd\n",
    "    #arr2d=np.asarray(pcd_sim.points)\n",
    "    x=np_array.copy()[:,0]\n",
    "    np_array[:,0]=np_array[:,2]\n",
    "    np_array[:,2]=x\n",
    "    np.save(npy_final_path+filename_,np_array)#.npy\n",
    "\n",
    "    #reconstructed_car= o3d.io.read_point_cloud(reconstructed_car_path +\"/\"+ filename_car)\n",
    "    #crop_invert=crop_invert_stitch(original_pcd,reconstructed_car, bbox)\n",
    "    #o3d.io.write_point_cloud(reconstructed_scene_path+\"/\"+filename_car,crop_invert)\n",
    "    #np_array=np.asarray(crop_invert.points)\n",
    "    #np.save(npy_final_path+filename_car,np_array)\n",
    "#\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d38b9705c2507b2c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#source_label_path = \"/home/omar/TUM/Masterarbeit/Data/m1695833/Sim2RealDistributionAlignedDataset/real/data/label/\"\n",
    "#pcd_real=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/cropped/sim/018840.pcd\")\n",
    "#pcd_sim=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/reconstructed_scene/sim/018845.pcd\")\n",
    "#arr=np.asarray(pcd_sim.points)\n",
    "#print(pcd_sim.points)\n",
    "#print(\"np shape: \" ,np.asarray(pcd_sim.points).shape)\n",
    "#arr2d=np.asarray(pcd_sim.points)\n",
    "#x=arr2d.copy()[:,0]\n",
    "#arr2d[:,0]=arr2d[:,2]\n",
    "#arr2d[:,2]=x\n",
    "#pcd = o3d.geometry.PointCloud()\n",
    "#pcd.points = o3d.utility.Vector3dVector(arr2d)\n",
    "#o3d.io.write_point_cloud(\"/home/omar/TUM/Data/sync.pcd\", pcd)\n",
    "#\n",
    "## Load saved point cloud and visualize it\n",
    "#pcd_load = o3d.io.read_point_cloud(\"/home/omar/TUM/Data/sync.pcd\")\n",
    "##o3d.visualization.draw_geometries([pcd_load])\n",
    "#pcd_car_recons=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/reconstructed_cropped/sim/020000.pcd\")\n",
    "#pcl=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/SeedFormer_2602_npy_zyx/real/points/018840.npy\")\n",
    "pcl=np.load(\"/home/omar/TUM/Data/SeedFormer_2602_npy/sim/points/015500.npy\")\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pcl)\n",
    "#box=[\"Car\" ,0.0, 0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.18, 1.9 ,4.88 ,1.56 ,6.55 ,1.01 ,-0.0]\n",
    "box=[\"Car\" ,0.0, 0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.18, 1.9 ,4.88 ,76.79 ,1.53,0.96 ,0.06]\n",
    "\n",
    "#pcd_cut=crop_invert_stitch(pcl,box)\n",
    "#pcd=pcd_cut+pcd_car_recons\n",
    "utils.visualize(pcl=pcd,bbox_coordinates=box)\n",
    "#utils.visualize(pcl=pcd_sim)\n",
    "#\n",
    "#utils.visualize(pcl=pcd_sim)\n",
    "#\n",
    "#utils.visualize(pcl=pcl)\n",
    "#\n",
    "#utils.visualize(pcl=pcd)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35be81a35c3b532b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#pcl=np.load(\"/home/omar/TUM/Data/SeedFormer_2602_npy/reconstructed/points/018840.npy\")\n",
    "pcd=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/cropped/real/018840.pcd\")\n",
    "print(len(pcd.points))\n",
    "#pcd = o3d.geometry.PointCloud()\n",
    "#pcd.points = o3d.utility.Vector3dVector(pcl)\n",
    "#box=[\"Car\" ,0.0, 0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.18, 1.9 ,4.88 ,1.56 ,6.55 ,1.01 ,-0.0]\n",
    "box=[\"Car\" ,0.0, 0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.18, 1.9 ,4.88 ,81.49 ,2.12,0.76 ,0.06]\n",
    "\n",
    "#pcd_cut=crop_invert_stitch(pcl,box)\n",
    "#pcd=pcd_cut+pcd_car_recons\n",
    "utils.visualize(pcl=pcd,bbox_coordinates=box)\n",
    "#utils.visualize(pcl=pcd_sim)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31785e53b0214b03",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "array2d=np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9],[10, 11, 12]])\n",
    "print(\"array2d : \",array2d)\n",
    "print(\"array2d shape \" , array2d.shape)\n",
    "print(\"-------------\")\n",
    "#print(\"transpose : \" ,array2d.T)\n",
    "#print(\"reshape:  \" ,array2d.reshape(-1).T)\n",
    "x=array2d.copy()[:,0]\n",
    "print(\"x col : \" ,array2d[:,0])\n",
    "\n",
    "print(\"z col : \" ,array2d[:,2])\n",
    "array2d[:,0]=array2d[:,2]\n",
    "print(\"x\",x)\n",
    "array2d[:,2]=x\n",
    "print(\"x col  after swap: \" ,array2d)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a4fc9750f895a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a0d01b44f3f54d9e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cb64edf1b021b3cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load simulation dataset\n",
    "simulation_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/sim\")\n",
    "simulation_dataloader = DataLoader(simulation_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=collate_fn)\n",
    "\n",
    "# Load real dataset\n",
    "real_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\")\n",
    "real_dataloader = DataLoader(real_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=collate_fn)\n",
    "\n",
    "# Select a subset of samples\n",
    "num_samples = 3\n",
    "\n",
    "# Apply the model and visualize differences\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "\n",
    "for dataset, dataloader, name in [(simulation_dataset, simulation_dataloader, \"Simulation\"), \n",
    "                                  (real_dataset, real_dataloader, \"Real\")]:\n",
    "    for i, data in enumerate(tqdm(dataloader, desc=f'Processing {name} dataset', unit='point cloud')):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        \n",
    "        inputs, paths = data\n",
    "        #print(paths)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        original_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(inputs.squeeze().cpu().numpy()))\n",
    "        original_pc.paint_uniform_color([1, 0, 0])  # Paint original point cloud in red\n",
    "\n",
    "        reconstructed_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(outputs.squeeze().cpu().numpy()))\n",
    "        reconstructed_pc.paint_uniform_color([0, 1, 0])  # Paint reconstructed point cloud in green\n",
    "\n",
    "        o3d.visualization.draw_geometries([original_pc, reconstructed_pc], window_name=f\"{name} - Sample {i+1}\")\n",
    "#model=None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7b4375fbe9eb442",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Notes#\n",
    "'''\n",
    "input threshold adjust - \n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c4231e6d2e1734",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
