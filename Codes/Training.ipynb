{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-24T14:16:58.627592Z",
     "start_time": "2024-03-24T14:16:54.588010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import seedformer_dim128\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import open3d as o3d\n",
    "import os\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset and Dataloader\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "Below is the implementation of custom dataset/dataloader. Additionally there is a collate function. The number of points in eaach pointcloud is \n",
    "different. In order to make them equal collate function is defined."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "717e2fba24cdcbb8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RacingDataset(Dataset):\n",
    "    def __init__(self,root_dir,target_points=2990):#4731\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = os.listdir(root_dir)\n",
    "        self.filter_file_list = self.filter_list()\n",
    "        self.target_points = target_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filter_file_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        pcd_path = os.path.join(self.root_dir,self.filter_file_list[index])\n",
    "        pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "        points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "\n",
    "        return points,pcd_path\n",
    "\n",
    "   \n",
    "    def filter_list(self):\n",
    "        '''\n",
    "        Filter the inputs so that only pcds with more than 50 points are included in the training\n",
    "        :return:\n",
    "        '''\n",
    "        filtered_list=[]\n",
    "        for filename in self.file_list:\n",
    "            pcd = o3d.io.read_point_cloud(os.path.join(self.root_dir,filename))\n",
    "            points = torch.tensor(pcd.points, dtype=torch.float32)\n",
    "            if len(points)>=0:\n",
    "                filtered_list.append(filename)\n",
    "        return filtered_list\n",
    "   \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T14:16:58.632715Z",
     "start_time": "2024-03-24T14:16:58.628877Z"
    }
   },
   "id": "18531201d491e956",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_114475/1991080591.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  pcd_pad_tens = torch.tensor(pcd_pad.points, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the largest point cloud\n",
    "pcd_pad = o3d.io.read_point_cloud(\"/home/omar/TUM/Data/cropped/sim/018840.pcd\")\n",
    "pcd_pad_tens = torch.tensor(pcd_pad.points, dtype=torch.float32)\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\", target_points=len(pcd_pad_tens))\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=8, collate_fn=utils.collate_fn)\n",
    "\n",
    "print(len(dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T14:17:00.491308Z",
     "start_time": "2024-03-24T14:16:58.633385Z"
    }
   },
   "id": "bb205b36c1489ab0",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e28a0ccc7563064"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Epoch 1/100:   0%|          | 0/750 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample xyz.shape  torch.Size([8, 3, 4731])\n",
      "sample npoints: -   2000\n",
      "sampled_xyz\n",
      "layer1 shape:  torch.Size([8, 128, 2000])\n",
      "sample xyz.shape  torch.Size([8, 3, 2000])\n",
      "sample npoints: -   1000\n",
      "sampled_xyz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/750 [00:01<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer2 shape:  torch.Size([8, 256, 1000])\n",
      "sample xyz.shape  torch.Size([8, 3, 1000])\n",
      "sample npoints: -   None\n",
      "sampled_xyz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [512, 131, 1, 1], expected input[8, 259, 1, 1000] to have 131 channels, but got 259 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device)  \u001B[38;5;66;03m# Move data to GPU if available\u001B[39;00m\n\u001B[1;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 20\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m losses \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m input_pc, output_pc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(inputs, outputs):\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m# Calculate Chamfer Distance loss using pytorch3d.loss.chamfer_distance\u001B[39;00m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/model.py:286\u001B[0m, in \u001B[0;36mSeedFormer.forward\u001B[0;34m(self, partial_cloud)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;124;03m    partial_cloud: (B, N, 3)\u001B[39;00m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;66;03m# Encoder\u001B[39;00m\n\u001B[0;32m--> 286\u001B[0m feat, patch_xyz, patch_feat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpartial_cloud\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# Decoder\u001B[39;00m\n\u001B[1;32m    289\u001B[0m pred_pcds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_decoder(feat, partial_cloud, patch_xyz, patch_feat)\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/model.py:296\u001B[0m, in \u001B[0;36mSeedFormer.forward_encoder\u001B[0;34m(self, partial_cloud)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_encoder\u001B[39m(\u001B[38;5;28mself\u001B[39m, partial_cloud):\n\u001B[1;32m    294\u001B[0m     \u001B[38;5;66;03m# feature extraction\u001B[39;00m\n\u001B[1;32m    295\u001B[0m     partial_cloud \u001B[38;5;241m=\u001B[39m partial_cloud\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[0;32m--> 296\u001B[0m     feat, patch_xyz, patch_feat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeat_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpartial_cloud\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# (B, feat_dim, 1)\u001B[39;00m\n\u001B[1;32m    298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m feat, patch_xyz, patch_feat\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/model.py:45\u001B[0m, in \u001B[0;36mFeatureExtractor.forward\u001B[0;34m(self, partial_cloud)\u001B[0m\n\u001B[1;32m     42\u001B[0m l2_points \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_2(l2_points, l2_xyz)\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayer2 shape: \u001B[39m\u001B[38;5;124m\"\u001B[39m, l2_points\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 45\u001B[0m l3_xyz, l3_points \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msa_module_3\u001B[49m\u001B[43m(\u001B[49m\u001B[43ml2_xyz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml2_points\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# (B, 3, 1), (B, out_dim, 1)\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayer3 shape: \u001B[39m\u001B[38;5;124m\"\u001B[39m, l3_points\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m l3_points, l2_xyz, l2_points\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/PointNet2.py:191\u001B[0m, in \u001B[0;36mPointNet_SA_Layer.forward\u001B[0;34m(self, xyz, points, sampled_xyz, npoints)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;66;03m#grouped_points = grouped_points.reshape(grouped_points.size(0), -1, grouped_points.size(-1))\u001B[39;00m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m conv, norm \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorms):\n\u001B[0;32m--> 191\u001B[0m     grouped_points \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(norm(\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrouped_points\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m    192\u001B[0m grouped_points \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_conv(grouped_points)\n\u001B[1;32m    193\u001B[0m new_points \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(grouped_points, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# (B, D', S)\u001B[39;00m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/TUM/Masterarbeit/Codes/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Given groups=1, weight of size [512, 131, 1, 1], expected input[8, 259, 1, 1000] to have 131 channels, but got 259 channels instead"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "#del model\n",
    "model=seedformer_dim128(up_factors=[1, 2, 2])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "epochs=100\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)  # Reduce LR by a factor of 0.1 every 30 epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss=0\n",
    "    # Wrap the DataLoader with tqdm to track progress\n",
    "    with tqdm(enumerate(dataloader, 0), total=len(dataloader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch') as pbar:\n",
    "        for i, data in pbar:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)  # Move data to GPU if available\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            losses = []\n",
    "\n",
    "            for input_pc, output_pc in zip(inputs, outputs):\n",
    "                # Calculate Chamfer Distance loss using pytorch3d.loss.chamfer_distance\n",
    "                loss, _ = chamfer_distance(input_pc.unsqueeze(0), output_pc.unsqueeze(0))\n",
    "                losses.append(loss)\n",
    "\n",
    "            loss = torch.mean(torch.stack(losses))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(loss=running_loss / (i + 1))  # Update tqdm progress bar with the current loss\n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "    print(f'Epoch {epoch+1} Loss: {running_loss / len(dataloader)}')  # Log the epoch loss\n",
    "\n",
    "print('Finished Training')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T14:17:03.082880Z",
     "start_time": "2024-03-24T14:17:00.492355Z"
    }
   },
   "id": "ca233b98555d8fc7",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save The Data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bea2b4076db53cd4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "simulation_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/sim\")\n",
    "simulation_dataloader = DataLoader(simulation_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=utils.collate_fn)\n",
    "\n",
    "# Load real dataset\n",
    "real_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\")\n",
    "real_dataloader = DataLoader(real_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=utils.collate_fn)\n",
    "utils.apply_and_save_res(dataset=real_dataset,dataloader=real_dataloader,model=model,savedir=\"/home/omar/TUM/Data/reconstructed_cropped/real\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dc7f9fe7611c357",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## \"Stitch\" the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6b07375205c94ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create and save the new dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5512f6b90a1a2862"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correcting Labels\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d239d3f92368e731"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_folder=\"/home/omar/TUM/data_MA/m1695833/Sim2RealDistributionAlignedDataset/sim/data/label/\"\n",
    "save_folder=\"/home/omar/TUM/Data/SeedFormer_2602_npy/sim/labels/\"\n",
    "for label in os.listdir(labels_folder):\n",
    "    file = open(labels_folder+label)\n",
    "    bbox=file.read()\n",
    "    bbox_correct=utils.correct_bbox_label(bbox)\n",
    "    file.close()\n",
    "    file_write=open(save_folder+label,\"w+\")\n",
    "    file_write.write(\" \".join(bbox_correct))\n",
    "    file_write.close()\n",
    "    print(bbox_correct)\n",
    "    #print(items)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51ba0cfa6adeb93d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reconstructed_car_path=\"/home/omar/TUM/Data/combined/sim/\"\n",
    "#bbox_path=\"/home/omar/TUM/data_MA/m1695833/Sim2RealDistributionAlignedDataset/sim/data/label\"\n",
    "\n",
    "#original_sim_path=\"/home/omar/TUM/data_MA/m1695833/Sim2RealDistributionAlignedDataset/sim/data/pcl/\"\n",
    "original_sim_path=\"/home/omar/TUM/Data/reconstructed_scene/sim/\"\n",
    "#reconstructed_scene_path=\"/home/omar/TUM/Data/reconstructed_scene/sim/\"\n",
    "npy_final_path=\"/home/omar/TUM/Data/SeedFormer_2602_npy_zyx/reconstructed/points/\"\n",
    "file_car_list=[]\n",
    "for filename_car in os.listdir(reconstructed_car_path):\n",
    "    file_car_list.append(filename_car)\n",
    "    txt=filename_car.replace('.pcd',\".txt\")\n",
    "   # bbox = (open(bbox_path+\"/\"+txt, \"r\")).read().split()\n",
    "    original_pcd = o3d.io.read_point_cloud(original_sim_path+filename_car)\n",
    "    filename_=filename_car.split(\".\")[0]\n",
    "    #if  (int)(filename_)<=24995:#<>\n",
    "        \n",
    "        #print(filename_)\n",
    "    np_array=np.asarray(original_pcd.points)#.pcd\n",
    "    #arr2d=np.asarray(pcd_sim.points)\n",
    "    x=np_array.copy()[:,0]\n",
    "    np_array[:,0]=np_array[:,2]\n",
    "    np_array[:,2]=x\n",
    "    np.save(npy_final_path+filename_,np_array)#.npy\n",
    "\n",
    "    #reconstructed_car= o3d.io.read_point_cloud(reconstructed_car_path +\"/\"+ filename_car)\n",
    "    #crop_invert=crop_invert_stitch(original_pcd,reconstructed_car, bbox)\n",
    "    #o3d.io.write_point_cloud(reconstructed_scene_path+\"/\"+filename_car,crop_invert)\n",
    "    #np_array=np.asarray(crop_invert.points)\n",
    "    #np.save(npy_final_path+filename_car,np_array)\n",
    "#\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d38b9705c2507b2c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#source_label_path = \"/home/omar/TUM/Masterarbeit/Data/m1695833/Sim2RealDistributionAlignedDataset/real/data/label/\"\n",
    "#pcd_real=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/cropped/sim/018840.pcd\")\n",
    "#pcd_sim=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/reconstructed_scene/sim/018845.pcd\")\n",
    "#arr=np.asarray(pcd_sim.points)\n",
    "#print(pcd_sim.points)\n",
    "#print(\"np shape: \" ,np.asarray(pcd_sim.points).shape)\n",
    "#arr2d=np.asarray(pcd_sim.points)\n",
    "#x=arr2d.copy()[:,0]\n",
    "#arr2d[:,0]=arr2d[:,2]\n",
    "#arr2d[:,2]=x\n",
    "#pcd = o3d.geometry.PointCloud()\n",
    "#pcd.points = o3d.utility.Vector3dVector(arr2d)\n",
    "#o3d.io.write_point_cloud(\"/home/omar/TUM/Data/sync.pcd\", pcd)\n",
    "#\n",
    "## Load saved point cloud and visualize it\n",
    "#pcd_load = o3d.io.read_point_cloud(\"/home/omar/TUM/Data/sync.pcd\")\n",
    "##o3d.visualization.draw_geometries([pcd_load])\n",
    "#pcd_car_recons=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/reconstructed_cropped/sim/020000.pcd\")\n",
    "#pcl=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/SeedFormer_2602_npy_zyx/real/points/018840.npy\")\n",
    "pcl=np.load(\"/home/omar/TUM/Data/SeedFormer_2602_npy/sim/points/015500.npy\")\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pcl)\n",
    "#box=[\"Car\" ,0.0, 0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.18, 1.9 ,4.88 ,1.56 ,6.55 ,1.01 ,-0.0]\n",
    "box=[\"Car\" ,0.0, 0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.18, 1.9 ,4.88 ,76.79 ,1.53,0.96 ,0.06]\n",
    "\n",
    "#pcd_cut=crop_invert_stitch(pcl,box)\n",
    "#pcd=pcd_cut+pcd_car_recons\n",
    "utils.visualize(pcl=pcd,bbox_coordinates=box)\n",
    "#utils.visualize(pcl=pcd_sim)\n",
    "#\n",
    "#utils.visualize(pcl=pcd_sim)\n",
    "#\n",
    "#utils.visualize(pcl=pcl)\n",
    "#\n",
    "#utils.visualize(pcl=pcd)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35be81a35c3b532b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#pcl=np.load(\"/home/omar/TUM/Data/SeedFormer_2602_npy/reconstructed/points/018840.npy\")\n",
    "pcd=o3d.io.read_point_cloud(\"/home/omar/TUM/Data/cropped/real/018840.pcd\")\n",
    "print(len(pcd.points))\n",
    "#pcd = o3d.geometry.PointCloud()\n",
    "#pcd.points = o3d.utility.Vector3dVector(pcl)\n",
    "#box=[\"Car\" ,0.0, 0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.18, 1.9 ,4.88 ,1.56 ,6.55 ,1.01 ,-0.0]\n",
    "box=[\"Car\" ,0.0, 0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.18, 1.9 ,4.88 ,81.49 ,2.12,0.76 ,0.06]\n",
    "\n",
    "#pcd_cut=crop_invert_stitch(pcl,box)\n",
    "#pcd=pcd_cut+pcd_car_recons\n",
    "utils.visualize(pcl=pcd,bbox_coordinates=box)\n",
    "#utils.visualize(pcl=pcd_sim)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31785e53b0214b03",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "array2d=np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9],[10, 11, 12]])\n",
    "print(\"array2d : \",array2d)\n",
    "print(\"array2d shape \" , array2d.shape)\n",
    "print(\"-------------\")\n",
    "#print(\"transpose : \" ,array2d.T)\n",
    "#print(\"reshape:  \" ,array2d.reshape(-1).T)\n",
    "x=array2d.copy()[:,0]\n",
    "print(\"x col : \" ,array2d[:,0])\n",
    "\n",
    "print(\"z col : \" ,array2d[:,2])\n",
    "array2d[:,0]=array2d[:,2]\n",
    "print(\"x\",x)\n",
    "array2d[:,2]=x\n",
    "print(\"x col  after swap: \" ,array2d)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a4fc9750f895a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a0d01b44f3f54d9e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cb64edf1b021b3cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load simulation dataset\n",
    "simulation_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/sim\")\n",
    "simulation_dataloader = DataLoader(simulation_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=collate_fn)\n",
    "\n",
    "# Load real dataset\n",
    "real_dataset = RacingDataset(root_dir=\"/home/omar/TUM/Data/cropped/real\")\n",
    "real_dataloader = DataLoader(real_dataset, batch_size=1, shuffle=True, num_workers=8,collate_fn=collate_fn)\n",
    "\n",
    "# Select a subset of samples\n",
    "num_samples = 3\n",
    "\n",
    "# Apply the model and visualize differences\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "\n",
    "for dataset, dataloader, name in [(simulation_dataset, simulation_dataloader, \"Simulation\"), \n",
    "                                  (real_dataset, real_dataloader, \"Real\")]:\n",
    "    for i, data in enumerate(tqdm(dataloader, desc=f'Processing {name} dataset', unit='point cloud')):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        \n",
    "        inputs, paths = data\n",
    "        #print(paths)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        original_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(inputs.squeeze().cpu().numpy()))\n",
    "        original_pc.paint_uniform_color([1, 0, 0])  # Paint original point cloud in red\n",
    "\n",
    "        reconstructed_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(outputs.squeeze().cpu().numpy()))\n",
    "        reconstructed_pc.paint_uniform_color([0, 1, 0])  # Paint reconstructed point cloud in green\n",
    "\n",
    "        o3d.visualization.draw_geometries([original_pc, reconstructed_pc], window_name=f\"{name} - Sample {i+1}\")\n",
    "#model=None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7b4375fbe9eb442",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Notes#\n",
    "'''\n",
    "input threshold adjust - \n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c4231e6d2e1734",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
